{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import bs4\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that receives as parameters the query we want to search, the numer of result you want to start your search and the number of results you want to request. As the API only lets you download 100 results at a time, in order to get the first 300 results (where the most meaningfull content is), we need to perform 3 calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requester(query, start, results):\n",
    "    \n",
    "    global df\n",
    "\n",
    "    headers = { \n",
    "    \"apikey\": \"your_api\"}\n",
    "\n",
    "    params = (\n",
    "   (\"q\",query),\n",
    "   (\"num\", results),\n",
    "   (\"start\", start)\n",
    "    )\n",
    "\n",
    "    resp = requests.get('https://app.zenserp.com/api/v2/search', headers=headers, params=params);\n",
    "\n",
    "    data = json.loads(resp.text)\n",
    "    df_partial = pd.json_normalize(data[\"organic\"])\n",
    "\n",
    "# if/else statement to concatenate results of iteration trough different starting points\n",
    "\n",
    "    if start == \"0\":\n",
    "        df = df_partial\n",
    "    else:\n",
    "        df=pd.concat([df, df_partial])\n",
    "\n",
    "#add a column with the query used\n",
    "    df[\"query\"] = query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block, start points are established, they are the variable that changes to perform the number of calls to the API. In this case, we want 100 results starting from 0, 100 results starting from 100, and 100 results starting from 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_points = [0, 100, 200]\n",
    "query = \"your_query\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in start_points:\n",
    "    requester(query, i, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a df with the first 300 results. Having the urls for each article will let us scrap the sites to search more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>destination</th>\n",
       "      <th>description</th>\n",
       "      <th>isAmp</th>\n",
       "      <th>images</th>\n",
       "      <th>isCarousel</th>\n",
       "      <th>moreUrl</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Noticias de Narcotráfico - Santa Fe</td>\n",
       "      <td>https://www.ellitoral.com/tags/narcotrafico</td>\n",
       "      <td>https://www.ellitoral.com › tags</td>\n",
       "      <td>Narcotráfico. Parte de los elementos incautado...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>narcotrafico site:ellitoral.com -impresa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Colombia propone una alianza latinoamericana p...</td>\n",
       "      <td>https://www.ellitoral.com/internacionales/colo...</td>\n",
       "      <td>https://www.ellitoral.com › colom...</td>\n",
       "      <td>Sep 10, 2023 — Colombia, al igual que otros pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>narcotrafico site:ellitoral.com -impresa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>México y Estados Unidos se unen contra narcotr...</td>\n",
       "      <td>https://www.ellitoral.com/internacionales/mexi...</td>\n",
       "      <td>https://www.ellitoral.com › mexico...</td>\n",
       "      <td>Jul 25, 2023 — México y Estados Unidos se unen...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>narcotrafico site:ellitoral.com -impresa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cayó una banda que modificaba llantas para lle...</td>\n",
       "      <td>https://www.ellitoral.com/sucesos/gendarmeria-...</td>\n",
       "      <td>https://www.ellitoral.com › sucesos</td>\n",
       "      <td>Nov 2, 2023 — Además de las detenciones, se lo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>narcotrafico site:ellitoral.com -impresa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendían drogas en plena ciudad de Rosario y fu...</td>\n",
       "      <td>https://www.ellitoral.com/sucesos/rosario-ahor...</td>\n",
       "      <td>https://www.ellitoral.com › sucesos</td>\n",
       "      <td>Nov 16, 2023 — La Dirección de Investigación s...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>narcotrafico site:ellitoral.com -impresa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   position                                              title  \\\n",
       "0         1                Noticias de Narcotráfico - Santa Fe   \n",
       "1         2  Colombia propone una alianza latinoamericana p...   \n",
       "2         3  México y Estados Unidos se unen contra narcotr...   \n",
       "3         4  Cayó una banda que modificaba llantas para lle...   \n",
       "4         5  Vendían drogas en plena ciudad de Rosario y fu...   \n",
       "\n",
       "                                                 url  \\\n",
       "0        https://www.ellitoral.com/tags/narcotrafico   \n",
       "1  https://www.ellitoral.com/internacionales/colo...   \n",
       "2  https://www.ellitoral.com/internacionales/mexi...   \n",
       "3  https://www.ellitoral.com/sucesos/gendarmeria-...   \n",
       "4  https://www.ellitoral.com/sucesos/rosario-ahor...   \n",
       "\n",
       "                             destination  \\\n",
       "0       https://www.ellitoral.com › tags   \n",
       "1   https://www.ellitoral.com › colom...   \n",
       "2  https://www.ellitoral.com › mexico...   \n",
       "3    https://www.ellitoral.com › sucesos   \n",
       "4    https://www.ellitoral.com › sucesos   \n",
       "\n",
       "                                         description  isAmp images isCarousel  \\\n",
       "0  Narcotráfico. Parte de los elementos incautado...  False    NaN        NaN   \n",
       "1  Sep 10, 2023 — Colombia, al igual que otros pa...  False    NaN        NaN   \n",
       "2  Jul 25, 2023 — México y Estados Unidos se unen...  False    NaN        NaN   \n",
       "3  Nov 2, 2023 — Además de las detenciones, se lo...  False    NaN        NaN   \n",
       "4  Nov 16, 2023 — La Dirección de Investigación s...  False    NaN        NaN   \n",
       "\n",
       "  moreUrl                                     query  \n",
       "0     NaN  narcotrafico site:ellitoral.com -impresa  \n",
       "1     NaN  narcotrafico site:ellitoral.com -impresa  \n",
       "2     NaN  narcotrafico site:ellitoral.com -impresa  \n",
       "3     NaN  narcotrafico site:ellitoral.com -impresa  \n",
       "4     NaN  narcotrafico site:ellitoral.com -impresa  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we proceed to clean the df, supressing irrelevant columns and dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first row that is not an article\n",
    "df = df[1:]\n",
    "\n",
    "# drop duplicates based on url\n",
    "df = df.drop_duplicates(subset=\"url\", ignore_index=True)\n",
    "\n",
    "# drop irrelevant columns\n",
    "\n",
    "df.drop(columns=[\"images\", \"isCarousel\", \"moreUrl\", \"isAmp\", \"destination\", \"position\"], inplace=True)\n",
    "\n",
    "# drop NaN values\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a function that searches for the date in the html of a given url. For that we use the library \"BeautifulSoup\", a similar procces will be done to retrieve title and content of the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with urls\n",
    "h = df.url.to_list()\n",
    "\n",
    "def date_extract(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    try:\n",
    "        a = soup.find('div',{'itemprop': 'datePublished'}).next_element\n",
    "        return a\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            a = soup.find('time').next_element\n",
    "            return a\n",
    "        except AttributeError:\n",
    "            return None\n",
    "\n",
    "\n",
    "#append dates to a list that will become the \"date\" column\n",
    "b = []\n",
    "\n",
    "for i in h:\n",
    "    b.append(date_extract(i))\n",
    "\n",
    "b\n",
    "df[\"date\"] = b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only numbers, \".\" and \"-\"\n",
    "df['date'] = df['date'].astype(str).str.replace('[^0-9\\-.]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform some transformations to the dates requested, deleting accesory characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = b\n",
    "\n",
    "#drop rows that contains NaN, thats how we previously tagged urls that where impossible to bring back a date for\n",
    "df = df[df['date'].notna()]\n",
    "\n",
    "df[\"date\"]=df[\"date\"].apply(str)\n",
    "#remove end of strings with accesory characters\n",
    "df[\"date\"] = df[\"date\"].str.slice(-10)\n",
    "#remove empty spaces\n",
    "df['date'] = df['date'].str.replace(' ', '')\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saco letras que puedan haber quedado\n",
    "date_list = df[\"date\"].to_list()\n",
    "\n",
    "date_list2 = []\n",
    "\n",
    "for i in date_list:\n",
    "    i = i.translate(str.maketrans('','','abcdefghijklmnñopqrstuvwxyz'))\n",
    "    date_list2.append(i)\n",
    "\n",
    "date_list2\n",
    "\n",
    "df[\"date\"] = date_list2\n",
    "\n",
    "df['date']=pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Title and content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una lista con las url\n",
    "h = df.url.to_list()\n",
    "\n",
    "def date_extract(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    try:\n",
    "        title = soup.find('h1',{'class': 'headline-text'}).next_element\n",
    "        title = str(title)\n",
    "        return title\n",
    "    except AttributeError:\n",
    "        return \"NaN\"\n",
    "\n",
    "\n",
    "#creo una lista nueva que voy a llenar iterando con la función date_extract()\n",
    "b = []\n",
    "\n",
    "for i in h:\n",
    "    b.append(date_extract(i))\n",
    "\n",
    "df[\"title\"] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title\"][df[\"title\"] == \"NaN\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df.url.to_list()\n",
    "\n",
    "def subt_extract(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    try:\n",
    "        subt_content = soup.findAll('p')\n",
    "        subtitle = subt_content[0]\n",
    "        subtitle = str(subtitle)\n",
    "        return subtitle\n",
    "\n",
    "    except AttributeError:\n",
    "        return \"NaN\"\n",
    "    except IndexError:\n",
    "        return \"indexerror\"\n",
    "\n",
    "b = []\n",
    "\n",
    "for i in h:\n",
    "    b.append(subt_extract(i))\n",
    "\n",
    "df[\"subtitle\"] = b\n",
    "\n",
    "\n",
    "#clean result from unwanted characters and brackets from the html source\n",
    "def clean(x):\n",
    "    x = re.sub(\"([\\<]).*?([\\>])\", \"\\g<1>\\g<2>\", x)\n",
    "    x = re.sub(\"[\\<].*?[\\>]\", \"\", x)\n",
    "    return x\n",
    "\n",
    "df[\"subtitle\"] = df[\"subtitle\"].apply(clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract content of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_extract(url):\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    try:\n",
    "        text_content = soup.findAll('p')\n",
    "        content = text_content[1:]\n",
    "        content = str(content)\n",
    "        return content\n",
    "\n",
    "    except AttributeError:\n",
    "        return \"NaN\"\n",
    "    except IndexError:\n",
    "        return \"indexerror\"\n",
    "\n",
    "b = []\n",
    "\n",
    "for i in h:\n",
    "    b.append(content_extract(i))\n",
    "\n",
    "df[\"content\"] = b\n",
    "\n",
    "#clean result from unwanted characters and brackets from the html source\n",
    "\n",
    "def clean(x):\n",
    "    x = re.sub(\"([\\<]).*?([\\>])\", \"\\g<1>\\g<2>\", x)\n",
    "    x = re.sub(\"[\\<].*?[\\>]\", \"\", x)\n",
    "    return x\n",
    "\n",
    "df[\"content\"] = df[\"content\"].apply(clean)\n",
    "\n",
    "df['content'] = df['content'].str.replace(r\"\\[\",\"\")\n",
    "df['content'] = df['content'].str.replace(r\"\\]\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results to xlsx for sharing and csv for further work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"file_name.csv\")\n",
    "df.to_excel(\"file_name.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
